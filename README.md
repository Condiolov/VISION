# Projeto Vision

Projeto dedicado a auxiliar pessoas com deficiÃªncia visual. Utiliza inteligÃªncia artificial para descrever o ambiente e reconhecer textos em imagens. **AtenÃ§Ã£o**: O sistema ainda apresenta algumas limitaÃ§Ãµes, como a descriÃ§Ã£o de objetos desnecessÃ¡rios, troca de valores e outras imprecisÃµes. 

## ğŸ¥ Lives Demonstrativas
- **Live 1:** [Assista aqui](https://www.youtube.com/watch?v=3Si2rxoU4yk)
- **Live 2:** [Assista aqui](https://www.youtube.com/watch?v=wCPHE51jPjM)

## ğŸ“‹ Requisitos
Para rodar o Projeto Vision, vocÃª precisarÃ¡ de:
- **PC com uma boa placa de vÃ­deo** para rodar o Ollama com o modelo **LLaMA 3.2-Vision**.
- **Celular Android** com **modo de depuraÃ§Ã£o por Wi-Fi ativado**.
- **Piper** para sÃ­ntese de voz, utilizando a voz do **Faber** ([Detalhes sobre o Piper](https://github.com/rhasspy/piper)).

## ğŸš€ InstalaÃ§Ã£o
Para instalar o projeto, execute:
```bash
bash 00_instalador.sh
```

### ConfiguraÃ§Ã£o do toque na tela (coordenadas)
Caso precise configurar o toque na tela para capturar a foto corretamente, edite o arquivo `1_tira_foto.sh` e ajuste a linha:
```bash
adb shell input tap X Y
```
Para encontrar os valores corretos de **X e Y**, ative o **Localizador de Ponteiro** nas OpÃ§Ãµes do Desenvolvedor do Android. Assim, as coordenadas serÃ£o exibidas na tela ao tocar no local desejado.

## ğŸ“Œ Exemplos de Uso

### 1ï¸âƒ£ SimulaÃ§Ã£o de leitura de uma conta de Ã¡gua
Capturar uma imagem e processÃ¡-la:
```bash
bash 0_vision.sh
```
ğŸ”Š **Resultado:** [SaÃ­da de Ã¡udio gerada](./exemplos/output1.wav)

### 2ï¸âƒ£ Leitura de texto no PC
Fazer com que o sistema leia um texto digitado:
```bash
python le_texto.py "Exemplo de como eu leio o texto!"
```
ğŸ”Š **Resultado:** [SaÃ­da de Ã¡udio gerada](./exemplos/output2.wav)

---

## ğŸ› ï¸ Melhorias Futuras
- Refinamento na descriÃ§Ã£o de objetos.
- ReduÃ§Ã£o de erros na leitura de valores.
- Melhor desempenho em diferentes tipos de texto e cenÃ¡rios.

**Projeto em desenvolvimento! Feedbacks sÃ£o bem-vindos.** ğŸš€